{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bzyL_4Y73N44"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "skzl2A9Kx6e0"
      },
      "outputs": [],
      "source": [
        "# This code is an extention of the cada code available at\n",
        "# https://github.com/thomashelling/cada\n",
        "#\n",
        "# coding=utf-8\n",
        "\n",
        "import networkx as nx\n",
        "from networkx.algorithms.community import asyn_fluidc\n",
        "from networkx.algorithms.community import greedy_modularity_communities as gmc\n",
        "import random\n",
        "import numpy as np\n",
        "import community\n",
        "import time\n",
        "import infomap\n",
        "import igraph as ig\n",
        "import leidenalg\n",
        "\n",
        "class cada():\n",
        "\tdef __init__(self, graph, algorithm='louvain', resolution=0.1):\n",
        "\t\t\n",
        "\t\t# First do community detection\n",
        "\t\tif algorithm == 'louvain':\n",
        "\t\t\tpartition = community.best_partition(graph, resolution=resolution)\n",
        "\t\telif algorithm == 'leiden':\n",
        "\t\t\tpartition = self.run_leiden(graph,resolution=resolution)\n",
        "\t\telif algorithm == 'fluid':\n",
        "\t\t\tpartition = self.run_fluid(graph)\n",
        "\t\telif algorithm == 'greedy':\n",
        "\t\t\tpartition = self.run_greedy(graph,resolution)\n",
        "\t\telse:\n",
        "\t\t\tpartition = self.run_infomap(graph)\n",
        "\t\t\n",
        "\t\tcommunities = set()\n",
        "\t\tfor node in graph.nodes():\n",
        "\t\t\tif node in partition:\n",
        "\t\t\t\tcommunities.add(partition[node])\n",
        "\n",
        "\t\tanom_score = {}\n",
        "\n",
        "\t\t# Compute anomaly score for each node\n",
        "\t\tfor node in graph.nodes():\n",
        "\t\t\tcomms = {}\n",
        "\t\t\tfor neighbor in graph.neighbors(node):\n",
        "\t\t\t\tif neighbor != node:\n",
        "\t\t\t\t\tif partition[neighbor] not in comms:\n",
        "\t\t\t\t\t\tcomms[partition[neighbor]] = 0\n",
        "\n",
        "\t\t\t\t\tcomms[partition[neighbor]] += 1\n",
        "\n",
        "\t\t\tif len(comms) > 0:\n",
        "\t\t\t\t# The number of communities it is connected to. \n",
        "\t\t\t\tcomms = np.array(list(comms.values()))\n",
        "\t\t\t\t# print('nr communities connected', comms)\n",
        "\t\t\t\tmax_com = np.max(comms)\n",
        "\t\t\t\t# print('Maxcommunity', max_com)\n",
        "\t\t\t\tcomms = comms / max_com\n",
        "\t\t\t\t# print('Communities normalized', comms)\n",
        "\t\t\t\tanom_score[node] = np.sum(comms)\t\t\n",
        "\t\t\t\t# print('Anomaly score., ', anom_score[node])\n",
        "\n",
        "\t\tself.anomaly_scores = sorted(anom_score.items(), key=lambda x: x[1])[::-1]\n",
        "\t\tself.n_nodes = graph.number_of_nodes()\n",
        "\n",
        "\tdef clf(self,n_injections):\n",
        "\t\t\"\"\"\n",
        "\t\tPredicts n_injections anomaly nodes \n",
        "\t\t\"\"\"\n",
        "\t\tpred = np.zeros(self.n_nodes,dtype=int)\n",
        "\t\t#worst_nodes = self.anomaly_scores[:n_injections][0]\n",
        "\t\tfor ind,anomaly in enumerate(self.anomaly_scores):\n",
        "\t\t\tif(ind>=n_injections):\n",
        "\t\t\t\tbreak\n",
        "\t\t\tpred[anomaly[0]] = 1\n",
        "\t\t\t\n",
        "\t\treturn pred\n",
        "\n",
        "\tdef run_leiden(self,graph,resolution):\n",
        "\t\t\"\"\"\n",
        "\t\tCreates partitions with the Leiden algorithm\n",
        "\t\t\"\"\"\n",
        "\t\th = ig.Graph.from_networkx(graph)\n",
        "\t\t#part = leidenalg.find_partition(h, leidenalg.ModularityVertexPartition)\n",
        "\t\t#part = leidenalg.find_partition(h, leidenalg.RBConfigurationVertexPartition,resolution_parameter = 0.5)\n",
        "\t\tpart = leidenalg.find_partition(h, leidenalg.CPMVertexPartition,resolution_parameter = resolution)\n",
        "\t\tpartition = {}\n",
        "\n",
        "\t\tfor ind,com in enumerate(part):\n",
        "\t\t\tfor node in com:\n",
        "\t\t\t\tpartition[node] = ind\n",
        "\n",
        "\t\treturn partition\n",
        "\n",
        "\tdef run_greedy(self,graph,resolution):\n",
        "\t\t\"\"\"\n",
        "\t\tCreates partitions with Clauset-Newman-Moore greedy modularity maximization\n",
        "\t\t\"\"\"\n",
        "\t\tbest_n = int(graph.number_of_nodes()/10)\n",
        "\t\tcommunities = gmc(graph,resolution=resolution,best_n=best_n)\n",
        "\t\tpartition = {}\n",
        "\t\tprint(f\"nr of coms={len(communities)}\")\n",
        "\t\tfor ind,com in enumerate(communities):\n",
        "\t\t\tfor node in com:\n",
        "\t\t\t\tpartition[node] = ind\n",
        "\t\t\n",
        "\t\treturn partition\n",
        "\n",
        "\tdef run_fluid(self,graph):\n",
        "\t\t\"\"\"\n",
        "\t\tCreates partitions with async_fluidc\n",
        "\t\t\"\"\"\n",
        "\t\tk = int(graph.number_of_nodes()/100)\n",
        "\t\tit = asyn_fluidc(graph,k=k)\n",
        "\t\tpartition = {}\n",
        "\n",
        "\t\tfor ind,com in enumerate(it):\n",
        "\t\t\tfor node in com:\n",
        "\t\t\t\tpartition[node] = ind\n",
        "\n",
        "\t\treturn partition\n",
        "\n",
        "\tdef run_infomap(self, graph):\n",
        "\t\t\"\"\"\n",
        "\t\tRuns Infomap with infomap package \n",
        "\t\t\"\"\"\n",
        "\t\tinfomapSimple = infomap.Infomap(\"--two-level --silent\")\n",
        "\t\tnetwork = infomapSimple.network\n",
        "\t\t\n",
        "\t\tfor e in graph.edges():\n",
        "\t\t\tnetwork.addLink(e[0], e[1])\n",
        "\n",
        "\t\tpartition = {}\n",
        "\t\tinfomapSimple.run()\n",
        "\t\tfor node in infomapSimple.iterTree():\n",
        "\t\t\tif node.isLeaf():\n",
        "\t\t\t\tpartition[node.physicalId] = node.moduleIndex()\n",
        "\n",
        "\t\treturn partition\n",
        "\n",
        "\tdef get_anomaly_scores(self, nr_anomalies=None):\n",
        "\t\t\"\"\"\n",
        "\t\tReturns tuple (node, anomaly_score) for either nr_anomalies or all\n",
        "\t\t\"\"\"\n",
        "\t\tif nr_anomalies:\n",
        "\t\t\treturn self.anomaly_scores[:nr_anomalies]\n",
        "\t\telse:\n",
        "\t\t\treturn self.anomaly_scores \n",
        "\n",
        "\tdef get_top_anomalies(self, nr_anomalies=100):\n",
        "\t\t\"\"\"\n",
        "\t\tReturns highest scoring anomalies\n",
        "\t\t\"\"\"\t\t\t\t\t\n",
        "\t\tanomalies = []\n",
        "\t\tfor anomaly in self.anomaly_scores[:nr_anomalies]:\n",
        "\t\t\tanomalies.append(anomaly[0])\n",
        "\n",
        "\t\treturn anomalies\n",
        "\n",
        "\tdef get_anomalies_threshold(self, threshold):\n",
        "\t\t\"\"\"\n",
        "\t\tReturns anomalies that are above a certain threshold.\n",
        "\t\t\"\"\"\n",
        "\t\tanomalies = []\n",
        "\n",
        "\t\tfor anomaly in self.anomaly_scores:\n",
        "\t\t\tif anomaly[1] > threshold:\n",
        "\t\t\t\tanomalies.append(anomaly[0])\n",
        "\t\t\telse:\n",
        "\t\t\t\tbreak\n",
        "\n",
        "\t\treturn anomalies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import f1_score\n",
        "from time import process_time as pt\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "wKHCjrKt3fV8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET1**"
      ],
      "metadata": {
        "id": "HXNVfBfF54k_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emails = pd.read_csv('email-EuAll.txt',sep='\\t',names=[\"Source\",\"Destination\"])"
      ],
      "metadata": {
        "id": "xlXuuMuP3SUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails"
      ],
      "metadata": {
        "id": "znfoYv7e3laR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails.dropna(inplace=True)\n",
        "emails.drop([3],axis=0,inplace=True)\n",
        "emails.reset_index(inplace=True,drop=True)"
      ],
      "metadata": {
        "id": "SM8-jLzo7nos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emails = emails.astype({'Source':'int'})\n",
        "emails = emails.astype({'Destination':'int'})"
      ],
      "metadata": {
        "id": "4VVPj19R27Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "email = nx.from_pandas_edgelist(emails, source='Source', target='Destination',create_using=nx.DiGraph)\n",
        "email = email.to_undirected()\n",
        "#email_in_degrees = sorted((d for n, d in email.in_degree()), reverse=True)\n",
        "#email_out_degrees = sorted((d for n, d in email.out_degree()), reverse=True)\n",
        "temp = nx.from_pandas_edgelist(emails, source='Source', target='Destination',create_using=nx.DiGraph)\n",
        "largest_cc =nx.subgraph(temp,max(nx.weakly_connected_components(temp),key=len))\n",
        "largest_cc = largest_cc.to_undirected()"
      ],
      "metadata": {
        "id": "JXjvD1ig91n-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Louvain\n",
        "cada_louvain = cada(email,algorithm='louvain')\n",
        "n_inj = int(10)\n",
        "pred_louvain = cada_louvain.clf(n_inj)"
      ],
      "metadata": {
        "id": "S8cbw8J83idO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import savetxt\n",
        "savetxt('louvain1.csv', pred_louvain, delimiter=',')"
      ],
      "metadata": {
        "id": "xwXkU4H83wfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET2**"
      ],
      "metadata": {
        "id": "Idk6MyhJ6Djw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "wiki = pd.read_csv('wiki-Talk.txt',sep='\\t',names=[\"Source\",\"Destination\"])"
      ],
      "metadata": {
        "id": "-3xbnd4p6D3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki"
      ],
      "metadata": {
        "id": "zUuSLYkW5J5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki.dropna(inplace=True)\n",
        "wiki.drop([3],axis=0,inplace=True)\n",
        "wiki.reset_index(inplace=True,drop=True)"
      ],
      "metadata": {
        "id": "QyyC-2wc5J5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki = wiki.astype({'Source':'int'})\n",
        "wiki = wiki.astype({'Destination':'int'})"
      ],
      "metadata": {
        "id": "5G6qeLdB5J5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wiki_g = nx.from_pandas_edgelist(wiki, source='Source', target='Destination',create_using=nx.DiGraph)\n",
        "wiki_g = wiki_g.to_undirected()\n",
        "#email_in_degrees = sorted((d for n, d in email.in_degree()), reverse=True)\n",
        "#email_out_degrees = sorted((d for n, d in email.out_degree()), reverse=True)"
      ],
      "metadata": {
        "id": "f3kUOQUh5J5n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Louvain\n",
        "cada_louvain = cada(wiki_g,algorithm='louvain')\n",
        "n_inj = int(100)\n",
        "pred_louvain = cada_louvain.clf(n_inj)"
      ],
      "metadata": {
        "id": "SnEVtgUc6LEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import savetxt\n",
        "savetxt('louvain2.csv', pred_louvain, delimiter=',')"
      ],
      "metadata": {
        "id": "go4KvFi26LEd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**DATASET3**"
      ],
      "metadata": {
        "id": "BbutxcfP6WRy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "twitch = pd.read_csv('large_twitch_edges.csv',names=[\"Source\",\"Destination\"])"
      ],
      "metadata": {
        "id": "fz_1Fa3q6V-w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitch.drop([0],axis=0,inplace=True)\n",
        "twitch.reset_index(inplace=True,drop=True)"
      ],
      "metadata": {
        "id": "NZrEExx7-Vx1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitch\n"
      ],
      "metadata": {
        "id": "Ycd6KVrK_n8r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitch = twitch.astype({'Source':'int'})\n",
        "twitch = twitch.astype({'Destination':'int'})"
      ],
      "metadata": {
        "id": "icydiLFV_zyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "twitch_g = nx.from_pandas_edgelist(twitch, source='Source', target='Destination',create_using=nx.DiGraph)\n",
        "twitch_g = twitch_g.to_undirected()\n",
        "\n",
        "#email_in_degrees = sorted((d for n, d in email.in_degree()), reverse=True)\n",
        "#email_out_degrees = sorted((d for n, d in email.out_degree()), reverse=True)"
      ],
      "metadata": {
        "id": "hBGG82mm_zyu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Louvain\n",
        "cada_louvain = cada(twitch_g,algorithm='louvain')\n",
        "n_inj = int(100)\n",
        "pred_louvain = cada_louvain.clf(n_inj)"
      ],
      "metadata": {
        "id": "52XHpC6v6tDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import savetxt\n",
        "savetxt('louvain3.csv', pred_louvain, delimiter=',')"
      ],
      "metadata": {
        "id": "bXyxgQDi6tDk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}